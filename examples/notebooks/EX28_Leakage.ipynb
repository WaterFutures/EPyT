{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "abe311aa",
   "metadata": {},
   "source": [
    "EPyT (EPANET 2.3) â€” FAVAD leakage demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1348168",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from epyt import epanet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ba81fb",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    # ===== Input file =====\n",
    "    INP = \"Net1.inp\"\n",
    "    d = epanet(INP)\n",
    "\n",
    "    q_unit = d.getFlowUnits()\n",
    "    p_unit = d.getOptionsPressureUnits()\n",
    "    print(f\"[Units] Flow={q_unit} | Pressure={p_unit}\")\n",
    "\n",
    "    # ===== Simulation settings =====\n",
    "    SIM_HOURS = 24\n",
    "    HYD_STEP_MIN = 60\n",
    "\n",
    "    d.setTimeSimulationDuration(SIM_HOURS * 3600)\n",
    "    d.setTimeHydraulicStep(HYD_STEP_MIN * 60)\n",
    "\n",
    "    n_links = d.getLinkCount()\n",
    "\n",
    "    # ===== Apply leakage to multiple links =====\n",
    "    # (LinkID, LC1, LC2)\n",
    "    leak_links = [\n",
    "        (\"21\", 1.0, 0.10),\n",
    "        (\"12\", 0.8, 0.05),\n",
    "        (\"31\", 0.9, 0.08),\n",
    "    ]\n",
    "\n",
    "    print(\"\\n===== APPLY LEAKAGE =====\")\n",
    "    leak_link_ids = [x[0] for x in leak_links]\n",
    "    leak_link_indices = []\n",
    "\n",
    "    for link_id, lc1, lc2 in leak_links:\n",
    "        link_idx = d.getLinkIndex(link_id)\n",
    "        if (link_idx is None) or (link_idx <= 0):\n",
    "            raise ValueError(f'Link ID \"{link_id}\" not found.')\n",
    "\n",
    "        leak_link_indices.append(link_idx)\n",
    "\n",
    "        d.setLinkLeakArea(link_idx, lc1)\n",
    "        d.setLinkExpansionProperties(link_idx, lc2)\n",
    "\n",
    "        print(f\"Applied leakage to link {link_id} (index {link_idx}): LC1={lc1:.6g}, LC2={lc2:.6g}\")\n",
    "\n",
    "    # ===== Run hydraulics and retrieve time series =====\n",
    "    # EPyT expects strings (not lists) for each attribute\n",
    "    res = d.getComputedHydraulicTimeSeries([\n",
    "        \"linkleakagerate\",\n",
    "        \"nodeleakageflow\",\n",
    "        \"emitterflow\",\n",
    "        \"demanddelivered\",\n",
    "        \"demandrequested\"]\n",
    "    )\n",
    "\n",
    "    time_s = np.asarray(res.Time).reshape(-1)\n",
    "    time_h = time_s / 3600.0\n",
    "\n",
    "    leak_link_ts = np.asarray(res.LinkLeakageRate)  # [time x links] (L/s)\n",
    "    leak_node_ts = np.asarray(res.NodeLeakageFlow)  # [time x nodes] (L/s)\n",
    "\n",
    "    # ===== Core results: totals, averages, peak, volumes =====\n",
    "    total_leak_ts_lps = np.nansum(leak_link_ts, axis=1)\n",
    "    avg_total_leak_lps = float(np.nanmean(total_leak_ts_lps))\n",
    "\n",
    "    if time_s.size >= 2:\n",
    "        total_leaked_volume_m3 = float(np.trapezoid(total_leak_ts_lps, time_s) / 1000.0)  # (L/s)*s -> L -> m^3\n",
    "    else:\n",
    "        total_leaked_volume_m3 = float(\"nan\")\n",
    "\n",
    "    idx_peak = int(np.nanargmax(total_leak_ts_lps))\n",
    "    peak_total_leak_lps = float(total_leak_ts_lps[idx_peak])\n",
    "    t_peak_h = float(time_h[idx_peak])\n",
    "\n",
    "    print(\"\\n===== LEAKAGE SUMMARY =====\")\n",
    "    print(f\"Average total leakage   : {avg_total_leak_lps:.3f} L/s\")\n",
    "    print(f\"Peak total leakage      : {peak_total_leak_lps:.3f} L/s at t = {t_peak_h:.2f} h\")\n",
    "    print(f\"Total leaked volume     : {total_leaked_volume_m3:.2f} m3/day (over {SIM_HOURS} h)\")\n",
    "\n",
    "    # ===== Per-link mean leakage and peak snapshot =====\n",
    "    avg_leak_per_link_lps = np.nanmean(leak_link_ts, axis=0).reshape(-1)  # [links]\n",
    "    leak_at_peak_lps = leak_link_ts[idx_peak, :].reshape(-1)              # [links]\n",
    "\n",
    "    # ===== Links by mean leakage =====\n",
    "    topN = 3\n",
    "    sorted_ix = np.argsort(-avg_leak_per_link_lps)  # descending\n",
    "    topN = min(topN, n_links)\n",
    "\n",
    "    top_link_index = sorted_ix[:topN] + 1  # EPANET link indexing is 1-based\n",
    "    top_link_leak = avg_leak_per_link_lps[sorted_ix[:topN]]\n",
    "\n",
    "    top_link_id = []\n",
    "    for idx0 in sorted_ix[:topN]:\n",
    "        idx1 = int(idx0 + 1)\n",
    "        top_link_id.append(str(d.getLinkNameID(idx1)))\n",
    "\n",
    "    print(f\"\\nTop-{topN} links by MEAN leakage (L/s):\")\n",
    "    for rank in range(topN):\n",
    "        print(f\"{rank+1:>2}. LinkIndex={int(top_link_index[rank])} | LinkID={top_link_id[rank]} | MeanLeak_LPS={top_link_leak[rank]:.6g}\")\n",
    "\n",
    "    # ===== Consistency checks for ALL leaky links (end nodes for each link) =====\n",
    "    print(\"\\n===== CONSISTENCY CHECKS (per leaky link) =====\")\n",
    "    tol_L = 0.01\n",
    "\n",
    "    for link_id, link_idx in zip(leak_link_ids, leak_link_indices):\n",
    "        nodes = d.getLinkNodesIndex(link_idx)  # [node1, node2] (1-based)\n",
    "        node1 = int(nodes[0])\n",
    "        node2 = int(nodes[1])\n",
    "\n",
    "        # numpy uses 0-based indices\n",
    "        node_cols = [node1 - 1, node2 - 1]\n",
    "        link_col = link_idx - 1\n",
    "\n",
    "        leak_nodes_total = float(np.nansum(leak_node_ts[:, node_cols]))\n",
    "        leak_link_total = float(np.nansum(leak_link_ts[:, link_col]))\n",
    "        abs_diff = abs(leak_link_total - leak_nodes_total)\n",
    "\n",
    "        print(\n",
    "            f\"Link {link_id} (idx {link_idx}) nodes ({node1},{node2}): \"\n",
    "            f\"LinkSum={leak_link_total:.4f} | NodeSum={leak_nodes_total:.4f} | Diff={abs_diff:.4f}\"\n",
    "        )\n",
    "\n",
    "        if not (abs_diff < tol_L):\n",
    "            raise AssertionError(f\"Leak mismatch for link {link_id}: link != nodes (Diff={abs_diff})\")\n",
    "\n",
    "    # ===== Plots =====\n",
    "    fig = plt.figure(figsize=(12, 8))\n",
    "    fig.suptitle(\"Leakage Results\")\n",
    "\n",
    "    # 1) Total leakage over time\n",
    "    ax1 = plt.subplot(2, 2, 1)\n",
    "    ax1.plot(time_h, total_leak_ts_lps, linewidth=1.5)\n",
    "    ax1.grid(True)\n",
    "    ax1.set_xlabel(\"Time (h)\")\n",
    "    ax1.set_ylabel(\"Total leakage (L/s)\")\n",
    "    ax1.set_title(\"Total leakage time series\")\n",
    "    ax1.plot(time_h[idx_peak], peak_total_leak_lps, marker=\"o\")\n",
    "    ax1.text(time_h[idx_peak], peak_total_leak_lps, f\"  Peak {peak_total_leak_lps:.2f} L/s @ {t_peak_h:.2f} h\", va=\"bottom\")\n",
    "\n",
    "    # 2) Leakage over time for each leaky link\n",
    "    ax2 = plt.subplot(2, 2, 2)\n",
    "    for link_id, link_idx in zip(leak_link_ids, leak_link_indices):\n",
    "        ax2.plot(time_h, leak_link_ts[:, link_idx - 1], linewidth=1.5, label=f\"Link {link_id}\")\n",
    "    ax2.grid(True)\n",
    "    ax2.set_xlabel(\"Time (h)\")\n",
    "    ax2.set_ylabel(\"Leakage (L/s)\")\n",
    "    ax2.set_title(\"Leakage on selected links\")\n",
    "    ax2.legend()\n",
    "\n",
    "    # 3) Links bar (mean leakage)\n",
    "    ax3 = plt.subplot(2, 2, 3)\n",
    "    ax3.bar(np.arange(1, topN + 1), top_link_leak)\n",
    "    ax3.grid(True)\n",
    "    ax3.set_xlabel(\"Rank\")\n",
    "    ax3.set_ylabel(\"Mean leakage (L/s)\")\n",
    "    ax3.set_title(\"Links by mean leakage\")\n",
    "    ax3.set_xticks(np.arange(1, topN + 1))\n",
    "    ax3.set_xticklabels(top_link_id)\n",
    "\n",
    "    # 4) Sum of leakage at end nodes (per leaky link)\n",
    "    ax4 = plt.subplot(2, 2, 4)\n",
    "    for link_id, link_idx in zip(leak_link_ids, leak_link_indices):\n",
    "        nodes = d.getLinkNodesIndex(link_idx)\n",
    "        node_cols = [int(nodes[0]) - 1, int(nodes[1]) - 1]\n",
    "        ax4.plot(time_h, np.nansum(leak_node_ts[:, node_cols], axis=1), linewidth=1.5, label=f\"Nodes of {link_id}\")\n",
    "    ax4.grid(True)\n",
    "    ax4.set_xlabel(\"Time (h)\")\n",
    "    ax4.set_ylabel(\"End-node leakage (L/s)\")\n",
    "    ax4.set_title(\"Leakage at end nodes of selected links\")\n",
    "    ax4.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # ===== Close EPANET object =====\n",
    "    d.unload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dfb6e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
